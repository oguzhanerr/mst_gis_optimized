{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Mobile Get Input Notebook - Phase 1\n",
    "\n",
    "**Phase 1 Improvements**: Consolidated configuration & improved helper functions for clarity and reliability.\n",
    "\n",
    "This notebook automates creation of terrain profiles for ITU-R P.1812-6 propagation prediction.\n",
    "\n",
    "## Workflow\n",
    "1. **Setup**: Configure transmitter location and parameters\n",
    "2. **Generate Receivers**: Create uniformly distributed receiver points\n",
    "3. **Extract Profiles**: Get terrain elevation and land cover data (via module)\n",
    "4. **Export**: Save profiles to CSV for batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_imports",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oz/Documents/mst_gis/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Union\n",
    "\n",
    "# Find and add project root to path\n",
    "possible_roots = [\n",
    "    Path.cwd(),\n",
    "    Path.cwd().parent,\n",
    "    Path.cwd().parent.parent,\n",
    "]\n",
    "\n",
    "project_root = None\n",
    "for root in possible_roots:\n",
    "    if (root / 'config_sentinel_hub.py').exists():\n",
    "        project_root = root\n",
    "        break\n",
    "\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import Sentinel Hub config\n",
    "import requests\n",
    "from config_sentinel_hub import (\n",
    "    SH_CLIENT_ID, SH_CLIENT_SECRET,\n",
    "    TOKEN_URL, PROCESS_URL, COLLECTION_ID,\n",
    ")\n",
    "from rasterio.io import MemoryFile\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "import elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_paths",
   "metadata": {},
   "source": [
    "## Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup_paths",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/oz/Documents/mst_gis\n",
      "Profiles dir: /Users/oz/Documents/mst_gis/data/input/profiles\n"
     ]
    }
   ],
   "source": [
    "# Detect project root by looking for src/ or config_sentinel_hub.py\n",
    "notebook_dir = Path.cwd()\n",
    "\n",
    "# Search for project root\n",
    "project_root = None\n",
    "for candidate in [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]:\n",
    "    if (candidate / 'src').exists() or (candidate / 'config_sentinel_hub.py').exists():\n",
    "        project_root = candidate\n",
    "        break\n",
    "\n",
    "if not project_root:\n",
    "    project_root = Path.cwd()  # Fallback to current dir\n",
    "\n",
    "profiles_dir = project_root / 'data' / 'input' / 'profiles'\n",
    "api_data_dir = project_root / 'data' / 'intermediate' / 'api_data'\n",
    "workflow_dir = project_root / 'data' / 'intermediate' / 'workflow'\n",
    "\n",
    "profiles_dir.mkdir(parents=True, exist_ok=True)\n",
    "api_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "workflow_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Profiles dir: {profiles_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_config",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmitter: (9.345, -13.40694)\n",
      "Azimuths: 36 | Profile points: 366\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Edit these parameters for your simulation\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    'TRANSMITTER': {\n",
    "        'tx_id': 'TX_0001',\n",
    "        'longitude': -13.40694,\n",
    "        'latitude': 9.345,\n",
    "        'antenna_height_tx': 57,\n",
    "        'antenna_height_rx': 10,\n",
    "    },\n",
    "    'P1812': {\n",
    "        'frequency_ghz': 0.9,\n",
    "        'time_percentage': 50,\n",
    "        'polarization': 1,\n",
    "    },\n",
    "    'RECEIVER_GENERATION': {\n",
    "        'max_distance_km': 11,\n",
    "        'azimuth_step': 10,\n",
    "        'distance_step': 0.5,\n",
    "        'sampling_resolution': 30,\n",
    "    },\n",
    "    'SENTINEL_HUB': {\n",
    "        'buffer_m': 11000,\n",
    "        'chip_px': 734,\n",
    "        'year': 2020,\n",
    "    },\n",
    "    'LCM10_TO_CT': {\n",
    "        100: 1, 80: 2, 30: 2, 40: 2, 70: 2, 110: 2, 254: 2,\n",
    "        20: 3, 50: 3, 10: 4, 60: 4, 90: 4,\n",
    "    },\n",
    "    'CT_TO_R': {1: 0, 2: 0, 3: 10, 4: 15, 5: 20},\n",
    "}\n",
    "\n",
    "# Derived values\n",
    "tx_lon = CONFIG['TRANSMITTER']['longitude']\n",
    "tx_lat = CONFIG['TRANSMITTER']['latitude']\n",
    "max_distance_km = CONFIG['RECEIVER_GENERATION']['max_distance_km']\n",
    "n_points = int(max_distance_km * 1000 / CONFIG['RECEIVER_GENERATION']['sampling_resolution'])\n",
    "azimuths = list(range(0, 360, CONFIG['RECEIVER_GENERATION']['azimuth_step']))\n",
    "distances = np.arange(\n",
    "    CONFIG['RECEIVER_GENERATION']['distance_step'],\n",
    "    max_distance_km + CONFIG['RECEIVER_GENERATION']['distance_step'],\n",
    "    CONFIG['RECEIVER_GENERATION']['distance_step']\n",
    ")\n",
    "\n",
    "print(f\"Transmitter: ({tx_lat}, {tx_lon})\")\n",
    "print(f\"Azimuths: {len(azimuths)} | Profile points: {n_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_transmitter",
   "metadata": {},
   "source": [
    "## Transmitter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "transmitter_class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmitter(tx_id='TX_0001', lon=-13.40694, lat=9.345, htg=57, f=0.9, pol=1, p=50, hrg=10)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Transmitter:\n",
    "    tx_id: str\n",
    "    lon: float\n",
    "    lat: float\n",
    "    htg: float\n",
    "    f: float\n",
    "    pol: int\n",
    "    p: float\n",
    "    hrg: float\n",
    "\n",
    "tx = Transmitter(\n",
    "    tx_id=CONFIG['TRANSMITTER']['tx_id'],\n",
    "    lon=CONFIG['TRANSMITTER']['longitude'],\n",
    "    lat=CONFIG['TRANSMITTER']['latitude'],\n",
    "    htg=CONFIG['TRANSMITTER']['antenna_height_tx'],\n",
    "    f=CONFIG['P1812']['frequency_ghz'],\n",
    "    pol=CONFIG['P1812']['polarization'],\n",
    "    p=CONFIG['P1812']['time_percentage'],\n",
    "    hrg=CONFIG['TRANSMITTER']['antenna_height_rx'],\n",
    ")\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_helpers",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define functions for credential resolution, land cover, and profile extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_credentials(verbose: bool = True, fallback_id=None, fallback_secret=None):\n",
    "    \"\"\"Get Sentinel Hub credentials from environment or fallback.\"\"\"\n",
    "    env_id = os.environ.get(\"SH_CLIENT_ID\", \"\").strip()\n",
    "    env_secret = os.environ.get(\"SH_CLIENT_SECRET\", \"\").strip()\n",
    "\n",
    "    if env_id and env_secret:\n",
    "        if verbose:\n",
    "            print(\"  ✓ Found credentials in environment variables\")\n",
    "        return env_id, env_secret\n",
    "\n",
    "    const_id = (fallback_id or SH_CLIENT_ID or \"\").strip()\n",
    "    const_secret = (fallback_secret or SH_CLIENT_SECRET or \"\").strip()\n",
    "\n",
    "    if not const_id or not const_secret or \"REPLACE_ME\" in str(const_id) or \"REPLACE_ME\" in str(const_secret):\n",
    "        raise RuntimeError(\"Credentials not found. Set SH_CLIENT_ID and SH_CLIENT_SECRET.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"  ✓ Found credentials in config file\")\n",
    "    return const_id, const_secret\n",
    "\n",
    "\n",
    "def meters_to_deg(lat, meters):\n",
    "    dlat = meters / 111_320.0\n",
    "    dlon = meters / (111_320.0 * math.cos(math.radians(lat)))\n",
    "    return dlat, dlon\n",
    "\n",
    "\n",
    "def get_token(client_id, client_secret):\n",
    "    r = requests.post(TOKEN_URL, data={\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret,\n",
    "    }, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"access_token\")\n",
    "\n",
    "\n",
    "def landcover_at_point(client_id, client_secret, lat, lon, token_url, process_url, collection_id, year=2020, buffer_m=1000, chip_px=32, save_path=None):\n",
    "    token = get_token(client_id, client_secret)\n",
    "    dlat, dlon = meters_to_deg(lat, buffer_m)\n",
    "    bbox = [lon - dlon, lat - dlat, lon + dlon, lat + dlat]\n",
    "\n",
    "    evalscript = \"\"\"//VERSION=3\n",
    "function setup() { return {input: [\\\"LCM10\\\"], output: {bands: 1, sampleType: \\\"UINT8\\\"}};}function evaluatePixel(s) { return [s.LCM10];}\"\"\"\n",
    "\n",
    "    body = {\n",
    "        \"input\": {\"bounds\": {\"bbox\": bbox, \"properties\": {\"crs\": \"http://www.opengis.net/def/crs/EPSG/0/4326\"}},\n",
    "                   \"data\": [{\"type\": f\"byoc-{collection_id}\", \"dataFilter\": {\"timeRange\": {\"from\": f\"{year}-01-01T00:00:00Z\", \"to\": f\"{year}-12-31T23:59:59Z\"}}}]},\n",
    "        \"output\": {\"width\": chip_px, \"height\": chip_px, \"responses\": [{\"identifier\": \"default\", \"format\": {\"type\": \"image/tiff\"}}]},\n",
    "        \"evalscript\": evalscript,\n",
    "    }\n",
    "\n",
    "    r = requests.post(process_url, json=body, headers={\n",
    "        \"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\", \"Accept\": \"image/tiff\"},\n",
    "        timeout=120)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if save_path:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "    with MemoryFile(r.content) as memfile:\n",
    "        with memfile.open() as ds:\n",
    "            arr = ds.read(1)\n",
    "\n",
    "    center_code = int(arr[arr.shape[0] // 2, arr.shape[1] // 2])\n",
    "    return center_code, arr\n",
    "\n",
    "\n",
    "def generate_profile_points(tx_lon, tx_lat, max_distance_km, n_points, azimuth_deg, tif_path, lcm10_to_ct, ct_to_r, zones_path=None):\n",
    "    # NOTE: elevation.seed() is called ONCE before the loop in extract_profiles cell\n",
    "    # DO NOT call it here to avoid redundant calls on every iteration\n",
    "    tx_gdf = gpd.GeoDataFrame(geometry=[Point(tx_lon, tx_lat)], crs=\"EPSG:4326\")\n",
    "    utm_crs = tx_gdf.estimate_utm_crs()\n",
    "    tx_utm = tx_gdf.to_crs(utm_crs)\n",
    "    center = tx_utm.geometry.iloc[0]\n",
    "\n",
    "    max_m = max_distance_km * 1000.0\n",
    "    step_m = max_m / (n_points - 1)\n",
    "    theta = math.radians(azimuth_deg)\n",
    "    dx_unit, dy_unit = math.sin(theta), math.cos(theta)\n",
    "\n",
    "    points_utm = [Point(center.x + i * step_m * dx_unit, center.y + i * step_m * dy_unit) for i in range(n_points)]\n",
    "    distances_km = [i * step_m / 1000.0 for i in range(n_points)]\n",
    "\n",
    "    gdf_utm = gpd.GeoDataFrame({\"id\": range(n_points), \"d\": distances_km, \"azimuth\": azimuth_deg}, geometry=points_utm, crs=utm_crs)\n",
    "    gdf = gdf_utm.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    gdf[\"zone\"] = 0\n",
    "    ct_codes = []\n",
    "    with rasterio.open(tif_path) as ds:\n",
    "        band = ds.read(1)\n",
    "        for geom in gdf.geometry:\n",
    "            row, col = ds.index(geom.x, geom.y)\n",
    "            if 0 <= row < ds.height and 0 <= col < ds.width:\n",
    "                ct_codes.append(int(band[row, col]))\n",
    "            else:\n",
    "                ct_codes.append(254)\n",
    "\n",
    "    gdf[\"ct\"] = ct_codes\n",
    "    gdf[\"Ct\"] = gdf[\"ct\"].map(lambda c: lcm10_to_ct.get(c, 2))\n",
    "    gdf[\"R\"] = gdf[\"Ct\"].map(lambda ct: ct_to_r.get(ct, 0))\n",
    "\n",
    "    # Sample elevation from VRT file\n",
    "    h = []\n",
    "    cache_dir = elevation.CACHE_DIR\n",
    "    vrt_path = Path(cache_dir) / \"SRTM1\" / \"SRTM1.vrt\"\n",
    "    \n",
    "    if vrt_path.exists():\n",
    "        try:\n",
    "            with rasterio.open(str(vrt_path)) as dem:\n",
    "                for geom in gdf.geometry:\n",
    "                    row, col = dem.index(geom.x, geom.y)\n",
    "                    if 0 <= row < dem.height and 0 <= col < dem.width:\n",
    "                        z = float(dem.read(1)[int(row), int(col)])\n",
    "                    else:\n",
    "                        z = 0.0\n",
    "                    h.append(z)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read DEM VRT ({e}), using 0 elevation\")\n",
    "            h = [0.0] * len(gdf)\n",
    "    else:\n",
    "        # Fallback: use zero elevation if VRT not available\n",
    "        print(f\"Warning: DEM VRT not found at {vrt_path}, using 0 elevation\")\n",
    "        h = [0.0] * len(gdf)\n",
    "\n",
    "    gdf[\"h\"] = h\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_receiver_gen",
   "metadata": {},
   "source": [
    "## Generate Receivers and Fetch Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helper_receiver_gen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 793 receiver points\n"
     ]
    }
   ],
   "source": [
    "def generate_receivers_radial_multi(\n",
    "    tx,\n",
    "    distances_km: Iterable[Union[int, float]],\n",
    "    azimuths_deg: Iterable[Union[int, float]],\n",
    "    include_tx_point: bool = False,\n",
    "):\n",
    "    \"\"\"Generate receivers on multiple rings around transmitter.\"\"\"\n",
    "    tx_gdf = gpd.GeoDataFrame(\n",
    "        {\"tx_id\": [tx.tx_id]},\n",
    "        geometry=[Point(tx.lon, tx.lat)],\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "    utm_crs = tx_gdf.estimate_utm_crs()\n",
    "    tx_utm = tx_gdf.to_crs(utm_crs)\n",
    "    tx_pt = tx_utm.geometry.iloc[0]\n",
    "\n",
    "    rows = []\n",
    "    rx_id = 1\n",
    "\n",
    "    if include_tx_point:\n",
    "        rows.append({\n",
    "            \"tx_id\": tx.tx_id,\n",
    "            \"rx_id\": 0,\n",
    "            \"distance_km\": 0.0,\n",
    "            \"geometry\": Point(tx.lon, tx.lat),\n",
    "        })\n",
    "\n",
    "    for d_km in distances_km:\n",
    "        radius_m = float(d_km) * 1000.0\n",
    "        for az in azimuths_deg:\n",
    "            theta = math.radians(float(az))\n",
    "            dx = radius_m * math.sin(theta)\n",
    "            dy = radius_m * math.cos(theta)\n",
    "            rx_utm = Point(tx_pt.x + dx, tx_pt.y + dy)\n",
    "            rx_ll = gpd.GeoSeries([rx_utm], crs=utm_crs).to_crs(\"EPSG:4326\").iloc[0]\n",
    "            rows.append({\n",
    "                \"tx_id\": tx.tx_id,\n",
    "                \"rx_id\": rx_id,\n",
    "                \"distance_km\": float(d_km),\n",
    "                \"azimuth_deg\": float(az),\n",
    "                \"geometry\": rx_ll,\n",
    "            })\n",
    "            rx_id += 1\n",
    "\n",
    "    return gpd.GeoDataFrame(rows, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Generate receiver points\n",
    "receivers = generate_receivers_radial_multi(tx, distances, azimuths, include_tx_point=True)\n",
    "print(f\"Generated {len(receivers)} receiver points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "landcover_fetch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FETCH LAND COVER FROM SENTINEL HUB =====\n",
      "\n",
      "  ✓ Found credentials in config file\n",
      "✓ Using cached GeoTIFF: /Users/oz/Documents/mst_gis/data/intermediate/api_data/lcm10_9.345_-13.40694_2020_buf11000m_734px.tif\n"
     ]
    }
   ],
   "source": [
    "# Fetch and cache land cover from Sentinel Hub\n",
    "print()\n",
    "print(\"===== FETCH LAND COVER FROM SENTINEL HUB =====\")\n",
    "print()\n",
    "client_id, client_secret = resolve_credentials(\n",
    "    fallback_id=SH_CLIENT_ID,\n",
    "    fallback_secret=SH_CLIENT_SECRET,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "lat = CONFIG['TRANSMITTER']['latitude']\n",
    "lon = CONFIG['TRANSMITTER']['longitude']\n",
    "buffer_m = CONFIG['SENTINEL_HUB']['buffer_m']\n",
    "chip_px = CONFIG['SENTINEL_HUB']['chip_px']\n",
    "year = CONFIG['SENTINEL_HUB']['year']\n",
    "\n",
    "out_tif = api_data_dir / f\"lcm10_{lat}_{lon}_{year}_buf{buffer_m}m_{chip_px}px.tif\"\n",
    "\n",
    "# Only fetch if not cached\n",
    "if not out_tif.exists():\n",
    "    print(f\"Fetching land cover for ({lat}, {lon})...\")\n",
    "    code, chip = landcover_at_point(\n",
    "        client_id, client_secret,\n",
    "        lat, lon,\n",
    "        token_url=TOKEN_URL,\n",
    "        process_url=PROCESS_URL,\n",
    "        collection_id=COLLECTION_ID,\n",
    "        year=year,\n",
    "        buffer_m=buffer_m,\n",
    "        chip_px=chip_px,\n",
    "        save_path=str(out_tif),\n",
    "    )\n",
    "    print(f\"✓ Successfully saved GeoTIFF: {out_tif}\")\n",
    "else:\n",
    "    print(f\"✓ Using cached GeoTIFF: {out_tif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_extract_export",
   "metadata": {},
   "source": [
    "## Extract Profiles and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extract_profiles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding elevation data...\n",
      "make: Nothing to be done for `download'.\n",
      "make: Nothing to be done for `all'.\n",
      "✓ Elevation data ready (0.04s)\n",
      "\n",
      "[1/36] Processing azimuth 0°... ✓ (4.76s)\n",
      "[2/36] Processing azimuth 10°... ✓ (4.72s)\n",
      "[3/36] Processing azimuth 20°... ✓ (4.74s)\n",
      "[4/36] Processing azimuth 30°... ✓ (4.70s)\n",
      "[5/36] Processing azimuth 40°... ✓ (4.70s)\n",
      "[6/36] Processing azimuth 50°... ✓ (4.71s)\n",
      "[7/36] Processing azimuth 60°... ✓ (4.70s)\n",
      "[8/36] Processing azimuth 70°... ✓ (4.71s)\n",
      "[9/36] Processing azimuth 80°... ✓ (4.72s)\n",
      "[10/36] Processing azimuth 90°... ✓ (4.69s)\n",
      "[11/36] Processing azimuth 100°... ✓ (4.73s)\n",
      "[12/36] Processing azimuth 110°... ✓ (4.71s)\n",
      "[13/36] Processing azimuth 120°... ✓ (4.73s)\n",
      "[14/36] Processing azimuth 130°... ✓ (4.72s)\n",
      "[15/36] Processing azimuth 140°... ✓ (4.73s)\n",
      "[16/36] Processing azimuth 150°... ✓ (4.75s)\n",
      "[17/36] Processing azimuth 160°... ✓ (4.75s)\n",
      "[18/36] Processing azimuth 170°... ✓ (4.75s)\n",
      "[19/36] Processing azimuth 180°... ✓ (4.77s)\n",
      "[20/36] Processing azimuth 190°... ✓ (4.75s)\n",
      "[21/36] Processing azimuth 200°... ✓ (4.75s)\n",
      "[22/36] Processing azimuth 210°... ✓ (4.80s)\n",
      "[23/36] Processing azimuth 220°... ✓ (4.76s)\n",
      "[24/36] Processing azimuth 230°... ✓ (4.79s)\n",
      "[25/36] Processing azimuth 240°... ✓ (4.81s)\n",
      "[26/36] Processing azimuth 250°... ✓ (4.83s)\n",
      "[27/36] Processing azimuth 260°... ✓ (4.81s)\n",
      "[28/36] Processing azimuth 270°... ✓ (4.83s)\n",
      "[29/36] Processing azimuth 280°... ✓ (4.85s)\n",
      "[30/36] Processing azimuth 290°... ✓ (4.84s)\n",
      "[31/36] Processing azimuth 300°... ✓ (4.84s)\n",
      "[32/36] Processing azimuth 310°... ✓ (4.84s)\n",
      "[33/36] Processing azimuth 320°... ✓ (4.83s)\n",
      "[34/36] Processing azimuth 330°... ✓ (4.86s)\n",
      "[35/36] Processing azimuth 340°... ✓ (4.87s)\n",
      "[36/36] Processing azimuth 350°... ✓ (4.85s)\n",
      "\n",
      "Timing Summary:\n",
      "  Seed time: 0.04s\n",
      "  Avg iteration: 4.77s\n",
      "  Total loop: 171.70s\n",
      "  Total time: 171.76s\n",
      "\n",
      "\n",
      "✓ Saved 36 profiles to /Users/oz/Documents/mst_gis/data/input/profiles/paths_oneTx_manyRx_11km.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# KEY OPTIMIZATION: Seed elevation ONCE before loop (not 36 times)\n",
    "print(\"Seeding elevation data...\")\n",
    "total_start = time.time()\n",
    "seed_start = time.time()\n",
    "try:\n",
    "    bounds = [tx_lon - 0.1, tx_lat - 0.1, tx_lon + 0.1, tx_lat + 0.1]\n",
    "    elevation.seed(bounds=bounds, max_download_tiles=9)\n",
    "    seed_time = time.time() - seed_start\n",
    "    print(f\"✓ Elevation data ready ({seed_time:.2f}s)\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: {e}\\n\")\n",
    "    seed_time = 0\n",
    "\n",
    "rows = []\n",
    "tif_path_str = str(out_tif)\n",
    "iter_times = []\n",
    "\n",
    "for i, az in enumerate(azimuths):\n",
    "    print(f\"[{i+1}/{len(azimuths)}] Processing azimuth {az}°...\", end=\" \", flush=True)\n",
    "    iter_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        gdf = generate_profile_points(\n",
    "            tx_lon, tx_lat,\n",
    "            max_distance_km,\n",
    "            n_points,\n",
    "            azimuth_deg=az,\n",
    "            tif_path=tif_path_str,\n",
    "            lcm10_to_ct=CONFIG['LCM10_TO_CT'],\n",
    "            ct_to_r=CONFIG['CT_TO_R'],\n",
    "            zones_path=None,\n",
    "        )\n",
    "        \n",
    "        geom_0 = gdf.geometry.iloc[0]\n",
    "        geom_last = gdf.geometry.iloc[-1]\n",
    "        phi_t, lam_t = float(geom_0.y), float(geom_0.x)\n",
    "        phi_r, lam_r = float(geom_last.y), float(geom_last.x)\n",
    "        \n",
    "        rows.append({\n",
    "            \"f\": CONFIG['P1812']['frequency_ghz'],\n",
    "            \"p\": CONFIG['P1812']['time_percentage'],\n",
    "            \"d\": [round(v, 3) for v in gdf[\"d\"].tolist()],\n",
    "            \"h\": [int(round(v)) if v else 0 for v in gdf[\"h\"].tolist()],\n",
    "            \"R\": gdf[\"R\"].tolist(),\n",
    "            \"Ct\": gdf[\"Ct\"].tolist(),\n",
    "            \"zone\": gdf[\"zone\"].tolist(),\n",
    "            \"htg\": CONFIG['TRANSMITTER']['antenna_height_tx'],\n",
    "            \"hrg\": CONFIG['TRANSMITTER']['antenna_height_rx'],\n",
    "            \"pol\": CONFIG['P1812']['polarization'],\n",
    "            \"phi_t\": phi_t,\n",
    "            \"phi_r\": phi_r,\n",
    "            \"lam_t\": lam_t,\n",
    "            \"lam_r\": lam_r,\n",
    "        })\n",
    "        iter_time = time.time() - iter_start\n",
    "        iter_times.append(iter_time)\n",
    "        print(f\"✓ ({iter_time:.2f}s)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"✗ ({type(e).__name__}: {str(e)[:60]})\")\n",
    "        iter_times.append(0)\n",
    "        continue\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "avg_time = sum(iter_times) / len(iter_times) if iter_times else 0\n",
    "print(f\"\\nTiming Summary:\")\n",
    "print(f\"  Seed time: {seed_time:.2f}s\")\n",
    "print(f\"  Avg iteration: {avg_time:.2f}s\")\n",
    "print(f\"  Total loop: {sum(iter_times):.2f}s\")\n",
    "print(f\"  Total time: {total_time:.2f}s\\n\")\n",
    "\n",
    "df_all = pd.DataFrame(rows)\n",
    "output_path = profiles_dir / f\"paths_oneTx_manyRx_{max_distance_km}km.csv\"\n",
    "df_all.to_csv(output_path, sep=\";\", index=False, decimal=\".\")\n",
    "\n",
    "print()\n",
    "print(f\"✓ Saved {len(df_all)} profiles to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Phase 1 Complete**:\n",
    "- Configuration consolidation with CONFIG dict\n",
    "- Helper functions for credentials and profile extraction\n",
    "- Real terrain profiles with Sentinel Hub land cover + cached elevation data\n",
    "- 36 profiles exported to CSV\n",
    "\n",
    "Next: Run batch_processor.py to process profiles through P.1812-6 model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
